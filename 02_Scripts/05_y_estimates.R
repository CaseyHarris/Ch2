#This script estimates water quality values for values
#of streamflow, using the expected values of water quality
#and uncertainty parameters generated by the MCMC script

#IMPORTANT NOTE about this script -- for extremely high/low 
#values of streamflow (out-of-range streamflow) for which no 
#actual water quality observations were available 
#between 2013 - 2022, this script uses the expected values 
#and uncertainty parameters associated with the highest/lowest 
#values of streamflow for which actual water quality observations 
#WERE available (min/max in-range streamflow).

#This has some implications for my results -- high/low
#estimated water quality are likely not as extreme as they
#may actually be, and definitely not as variable as they
#may actually be (because they are all pulled out of a 
#distribution using the same expected value and uncertainty
#parameter). Also, the credible intervals of estimated
#water quality are likely narrower than they may actually be.

#The y value files generated by this script are the past and future
#estimates of water quality used in further scripts

library(tidyverse)
library(data.table)
library(readxl)
library(foreach)
library(doParallel)

#WQ list
wq_names <- list.files("01_Data/Redone wq and flow")
#wq_names <- list.files("/blue/carpena/caseyharris/Ch2/WQ")
wq_names <- data.frame(wq_names) %>%
  filter(str_detect(wq_names, "Lithia|Morris")) %>%
  filter(str_detect(wq_names, "Alkalinity|Color|Fluoride|Iron|Manganese|Nitrogen|TOC|Phosphorus|Turbidity"))
unique(wq_names$wq_names)

#Max and min flow values and wq values
max_min <- read.csv("03_Results/max_min.csv")
#max_min <- read.csv("/blue/carpena/caseyharris/Ch2/max_min.csv")

#Models to use
model_names <- read_excel("C:/Users/cshar/Desktop/Ch2_git/Ch2/01_Data/Vgrids_realization_list.xlsx", sheet="Numbering", col_names=c("Realiz_num", "Scenario", 1:18), skip=2)
#model_names <- read_excel("/blue/carpena/caseyharris/Ch2/Vgrids_realization_list.xlsx", sheet="Numbering", col_names=c("Realiz_num", "Scenario", 1:18), skip=2)
colnames(model_names) <- make.names(colnames(model_names))
model_names1 <- model_names %>%
  mutate(Chang_item = X4,
         model = Scenario) %>%
  select(model, Chang_item) %>%
  mutate(model = str_remove(model, "_rcp85")) %>%
  mutate(model = str_remove_all(model, "'"))
add_names <- data.frame("model"=c("USGS", "USGS"), "Chang_item"=c(0,1369))
model_names1 <- model_names1 %>%
  bind_rows(add_names)
model_names2 <- model_names1 %>%
  mutate(per = case_when(Chang_item<=126 & Chang_item!=4 ~ "1989-2012",
                         Chang_item>=649 & Chang_item<=672 ~ "2030-2060",
                         Chang_item>=673 & Chang_item!=1369 ~ "2070-2100",
                         Chang_item==4 ~ "1989-2005",
                         Chang_item==1369 ~ "2010-2019",
                         TRUE ~ NA_character_))
model_names2 <- model_names2 %>%
  filter(str_detect(model, "Hargreaves") & !str_detect(model, "NLDAS"))
rm(add_names)
rm(model_names)
rm(model_names1)

#Flow data
# flow_Alaf_Hills <- read.csv("C:/Users/cshar/OneDrive - University of Florida/Online_diss_files/Ch2/Large files/Data/flow_Alaf_Hills.csv")
# #flow_Alaf_Hills <- read.csv("/blue/carpena/caseyharris/Ch2/flow_Alaf_Hills.csv")
flow_jason <- read.csv("C:/Users/cshar/OneDrive - University of Florida/Online_diss_files/Ch2/Large files/Data/flow_Jason1.csv")
#flow_jason <- read.csv("/blue/carpena/caseyharris/Ch2/flow_Jason1.csv")

stopCluster(cluster)
#cluster <- makeCluster(3)
#registerDoParallel(cluster)

#This actually needs to be the actual daily flows, use the right parameters from mcmc to get individual estimates of flow for each day/sim

i=4
# foreach(i = 1:length(wq_names$wq_names),
#         .packages=c('tidyverse', 'data.table', 'readxl')) %dopar% {
for (i in 1:length(wq_names$wq_names)) {
          
          title_use <- gsub(".csv", "", wq_names$wq_names[i])
          min_use <- max_min$value[max_min$title==title_use & max_min$name=="min_flow_obs_wq_2013_2022"]
          max_use <- max_min$value[max_min$title==title_use & max_min$name=="max_flow_obs_wq_2013_2022"]
          
          cal_val <- fread(paste0("01_Data/CQ/", title_use, ".csv", sep=""))
          cal_val <- cal_val %>%
            mutate(row_number = row_number())
          
          mcmc_summary <- fread(paste("03_Results/MCMC/", title_use, ".csv", sep=""))
          #mcmc_summary <- fread(paste0("/blue/carpena/caseyharris/Ch2/JAGS/MCMC/", title_use, ".csv", sep=""))
          mcmc_r <- as.data.frame(mcmc_summary$r)
          
          mcmc_trans <- mcmc_summary %>%
            select(-r) %>%
            t()
          mcmc_trans <- as.data.frame(mcmc_trans)
          mcmc <- cal_val %>%
            bind_cols(mcmc_trans) %>%
            arrange(row_number)
          
          mcmc_dups <- mcmc %>% #there are duplicate flows in mcmc when more than 1 water quality sample is taken at the same flow
            select(Q_cfs_log_round)
          mcmc$dups <- duplicated(mcmc_dups)
          
          mcmc1 <- mcmc %>%
            filter(dups==FALSE) %>% #removes extra copy of duplicates
            select(-dups)
          
          if (str_detect(title_use, "Alafia")) {
            flow_jason1 <- flow_jason %>%
              filter(site=="Alafia")
          } else if (str_detect(title_use, "Morris")) {
            flow_jason1 <- flow_jason %>%
              filter(site=="Hillsborough")
          }
          
          wq_flow <- flow_jason1 %>%
            mutate(Q_cfs_log_round = round(Q_cfs_log_round, 3)) %>%
            left_join(model_names2) %>%
            filter(!is.na(model)) %>%
            mutate(abv_bel = case_when(Q_cfs_log_round<min_use ~ "below",
                                       Q_cfs_log_round>max_use ~ "above",
                                       TRUE ~ "fine")) %>%
            mutate(Q_cfs_log_round_use = case_when(abv_bel=="below" ~ min_use,
                                                     abv_bel=="above" ~ max_use,
                                                     abv_bel=="fine" ~ Q_cfs_log_round)) %>%
            select(site, model, per, date, Chang_item, Realiz_num, abv_bel, Q_cfs_log_round, Q_cfs_log_round_use) %>%
            left_join(mcmc1, by=c("Q_cfs_log_round_use"="Q_cfs_log_round")) %>%
            select(-Chang_item, -Realiz_num, -row_number)
          
          mcmc_r$r <- mcmc_r$'mcmc_summary$r'
          mcmc_r <- mcmc_r %>%
            select(r)
          
          j=1
          k=5
          y_vals <- matrix(nrow=length(wq_flow$site), ncol=length(mcmc_r$r))
          for (j in 1:length(mcmc_r$r)) {
            
            r <- mcmc_r$r[j]
            
            for (k in 1:length(wq_flow$site)) {
              
              y_vals[k,j] <- rgamma(1, r, r/wq_flow[k,j+9])
              
            }
            
            print(j)
            
          }
          
          y_vals <- as.data.frame(y_vals)
          y <- data.frame("wq_name"=wq_flow$title, wq_flow[,1:7], "wq_orig"=wq_flow$wq_orig, y_vals)

          write.csv(y, paste("C:/Users/cshar/OneDrive - University of Florida/Online_diss_files/Ch2/Large files/Results/y/", title_use, ".csv", sep=""), row.names=FALSE)
          
          rm(y)
          rm(y_vals)
          rm(wq_flow)
          rm(mcmc1)
          rm(mcmc_trans)
          rm(mcmc_summary)
          gc()
}
